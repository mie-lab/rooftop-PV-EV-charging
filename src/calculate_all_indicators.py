import datetime
import os

import pandas as pd
from sqlalchemy import create_engine

# import database login information
from src.db_login import DSN
from src.methods.loading_and_preprocessing import load_and_prepare_baseline_data, load_and_prepare_scenario_raw_data, \
    get_id_matching_dict, get_inverse_id_matching_dict
from src.table_information import ecar_table_info

def check_user_plausibilty(baseline_data, data):
    vins_baseline = baseline_data['vin'].unique()
    vins_data = data['vin'].unique()

    for ix, vin_b in enumerate(vins_baseline):
        assert vin_b == vins_data[ix], f"only in data: {set(vins_data) - set(vins_baseline)}," \
                                       f" only in baseline {set(vins_baseline) - set(vins_data)}"

    return True

def parse_dates(data_raw):
    data = data_raw.copy()
    data['start'] = pd.to_datetime(data['start'])
    data['end'] = pd.to_datetime(data['end'])

    return data


output_folder = os.path.join('.', 'data', 'output', 'PVMODEL_SPV170')

baseline = pd.read_csv(os.path.join(output_folder, 'results_baseline.csv'))
baseline = parse_dates(baseline).sort_values('start')

scenario1 = pd.read_csv(os.path.join(output_folder, 'results_scenario1.csv'))
scenario1 = parse_dates(scenario1).sort_values('start')

scenario2 = pd.read_csv(os.path.join(output_folder, 'results_scenario2.csv'))
scenario2 = parse_dates(scenario2).sort_values('start')

scenario3 = pd.read_csv(os.path.join(output_folder, 'results_scenario3.csv'))
scenario3 = parse_dates(scenario3).sort_values('start')

coverage_by_scenario = pd.read_csv(os.path.join(output_folder, 'coverage_by_scenario.csv'))

# %%%%%%%%%%%%%%%%%%%%%%%%
print("number of users in sc2 with >= 0.95 coverage is: {}".format(
    coverage_by_scenario[coverage_by_scenario['scenario2'] >= 0.95].shape[0]))

########################### NB of users ###################################
path_to_data_folder = os.path.join('.', 'data')
output_folder = os.path.join(path_to_data_folder, 'output', 'PVMODEL_SPV170')

filepath = os.path.join(path_to_data_folder, 'car_is_at_home_table_UTC.csv')
filepath_baseline = os.path.join(path_to_data_folder, 'data_baseline.csv')

data_baseline = load_and_prepare_baseline_data(filepath_baseline)
data = load_and_prepare_scenario_raw_data(filepath)

# compute the columns
#     1) electricity generated by PV in kWH
#     2) electricity needed by car in kWH
# data = compute_additional_columns(data, drop_debug_columns=False)
# data_baseline = compute_additional_columns(data_baseline)

# validate that both datasets have exactly the same users
check_user_plausibilty(data_baseline, data)
users_final = data['vin'].unique()
nb_of_users_final = users_final.shape

print(10 * '%')
print('Number of users indicators')
print('\t final number of users: {}'.format(nb_of_users_final))

######################charging in baseline ###############################################################
total_energy_consumed_mwh = baseline['needed_by_car'].sum() / 1000
total_energy_charged_mwh = baseline['charged_from_pv'].sum() / 1000 + baseline['charged_from_outside'].sum() / 1000
total_energy_charged_home_mwh = baseline.loc[baseline.is_home, 'charged_from_pv'].sum() / 1000 \
                                + baseline.loc[baseline.is_home, 'charged_from_outside'].sum() / 1000

print(10 * '%')
print('charging')
print('\t total energy charged:  {} MWh'.format(total_energy_charged_mwh))
print('\t total energy charged at home:  {} MWh'.format(total_energy_charged_home_mwh))
print('\t percentage charged at home:  {} %'.format(total_energy_charged_home_mwh / total_energy_charged_mwh))
print('\t total energy consumed: {} MWh'.format(total_energy_consumed_mwh))

##########################BEV data descriptors ################################################

# get raw data
min_date = datetime.datetime(year=2017, month=2, day=1)
max_date = datetime.datetime(year=2018, month=12, day=31)
engine = create_engine('postgresql://{user}:{password}@{host}:{port}/{dbname}'.format(**DSN))

ecar_data_query = """select id, vin, zustand, timestamp_start_utc,
                    timestamp_end_utc, soc_customer_start, soc_customer_end,
                   user_id, km_stand_start, km_stand_end, consumed_electric_energy_total
                   from {schema_single}.{ecar_table_name_single}""".format(**ecar_table_info)

ecar_data = pd.read_sql(ecar_data_query, engine)
ecar_data.set_index('vin', inplace=True)

# drop data where timestamps are not plausible
ix = ecar_data['timestamp_start_utc'] <= ecar_data['timestamp_end_utc']
ecar_data = ecar_data[ix]

# filter timestamps
ecar_data = ecar_data[ecar_data['timestamp_start_utc'] >= min_date]
ecar_data = ecar_data[ecar_data['timestamp_end_utc'] <= max_date]

# filter by vins:
ecar_data = ecar_data[ecar_data.index.isin(users_final)]
nb_of_entries = ecar_data.shape[0]
nb_of_segments = scenario1.shape[0]
nb_of_drives = ecar_data[ecar_data['zustand'] == 'fahrt'].shape[0]
nb_of_charging = ecar_data[ecar_data['zustand'] == 'laden'].shape[0]
nb_of_km_offset = ecar_data.groupby(level=0)['km_stand_end'].min()
nb_of_km = ecar_data.groupby(level=0)['km_stand_end'].max() - nb_of_km_offset
nb_of_km_sum = nb_of_km.sum()
nb_of_km_avg = nb_of_km.mean()
consumed_energy_total = ecar_data.loc[ecar_data[
                                          'consumed_electric_energy_total'] < 100, 'consumed_electric_energy_total'].sum() / 1000
print(10 * '%')
print('BEV usage indicators')
print('\t Number of entries: {}'.format(nb_of_entries))
print('\t Number of segments: {}'.format(nb_of_segments))
print('\t Number of drives: {}'.format(nb_of_drives))
print('\t Number of charging process: {}'.format(nb_of_charging))
print('\t total km driven: {}'.format(nb_of_km_sum))
print('\t average km per person: {}'.format(nb_of_km_avg))

### final homes of users.
filepath = os.path.join(path_to_data_folder,
                        "manual_validation.csv")
validation = pd.read_csv(filepath, sep=';', encoding='latin-1')

inverse_matching_dict = get_inverse_id_matching_dict(os.path.join(path_to_data_folder,
                                                                  "vin_id_matching.csv"))
matching_dict = get_id_matching_dict(os.path.join(path_to_data_folder,
                                                  "vin_id_matching.csv"))
users_final_ids = pd.Series(users_final).map(inverse_matching_dict)
validation = validation.loc[validation['ID'].isin(users_final_ids)]

print("EFH: {}".format(validation[validation['EFH'] == 1].shape[0]))
print("ZFH: {}".format(validation[validation['ZFH'] == 1].shape[0]))
print("MFH: {}".format(validation[validation['MFH'] == 1].shape[0]))

# only keep ids of users that live in a single home (validation['EFH'] == 1)
# and were we were able to correctly recognize the roof area (validation['Brauchbar'] == 1)
good_userids_ix = (((validation['Brauchbar'] == 1) & (validation['EFH'] == 1)) |
                   ((validation['Brauchbar'] == 1) & (~validation['reduction_factor'].isna())))
good_userids = validation.loc[good_userids_ix, 'ID']
